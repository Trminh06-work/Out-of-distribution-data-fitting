\begin{thebibliography}{10}

\bibitem{8697857}
P.~P. Shinde and S.~Shah, ``A review of machine learning and deep learning applications,'' in {\em 2018 Fourth International Conference on Computing Communication Control and Automation (ICCUBEA)}, pp.~1--6, 2018.

\bibitem{Janiesch_2021}
C.~Janiesch, P.~Zschech, and K.~Heinrich, ``Machine learning and deep learning,'' {\em Electronic Markets}, vol.~31, p.~685–695, Apr. 2021.

\bibitem{lecun2015deep}
Y.~LeCun, Y.~Bengio, and G.~Hinton, ``Deep learning,'' {\em Nature}, vol.~521, no.~7553, pp.~436--444, 2015.

\bibitem{rane2024applications}
N.~Rane, S.~K. Mallick, O.~Kaya, and J.~Rane, ``Applications of deep learning in healthcare, finance, agriculture, retail, energy, manufacturing, and transportation: A review,'' in {\em Applied Machine Learning and Deep Learning: Architectures and Techniques}, ch.~7, pp.~132--152, Deep Science Publishing, October 2024.

\bibitem{jordan2015machine}
M.~I. Jordan and T.~M. Mitchell, ``Machine learning: Trends, perspectives, and prospects,'' {\em Science}, vol.~349, no.~6245, pp.~255--260, 2015.

\bibitem{russell2021aima}
S.~J. Russell and P.~Norvig, {\em Artificial Intelligence: A Modern Approach}.
\newblock Hoboken, NJ: Pearson, 4~ed., 2021.

\bibitem{malinin2021shifts}
A.~Malinin, N.~Band, G.~Chesnokov, Y.~Gal, M.~Gales, A.~Noskov, A.~Ploskonosov, L.~Ostroumova~Prokhorenkova, I.~Provilkov, V.~Raina, V.~Raina, M.~Shmatova, P.~Tigas, and B.~Yangel, ``Shifts: A dataset of real distributional shift across multiple large-scale tasks,'' 07 2021.

\bibitem{tamang2025handlingoutofdistributiondatasurvey}
L.~Tamang, M.~R. Bouadjenek, R.~Dazeley, and S.~Aryal, ``Handling out-of-distribution data: A survey,'' 2025.

\bibitem{quinonero2009datasetshift}
J.~Qui{\~n}onero-Candela, M.~Sugiyama, A.~Schwaighofer, and N.~D. Lawrence, {\em Dataset Shift in Machine Learning}.
\newblock Cambridge, MA: The MIT Press, 2009.

\bibitem{koh2021wilds}
P.~W. Koh, S.~Sagawa, H.~Marklund, S.~M. Xie, M.~Zhang, A.~Balsubramani, W.~Hu, M.~Yasunaga, R.~Lanas~Phillips, S.~Beery, J.~Leskovec, A.~Kundaje, E.~Pierson, S.~Levine, C.~Finn, and P.~Liang, ``Wilds: A benchmark of in-the-wild distribution shifts,'' {\em arXiv preprint arXiv:2012.07421}, 2020.

\bibitem{gulrajani2020searchlostdomaingeneralization}
I.~Gulrajani and D.~Lopez-Paz, ``In search of lost domain generalization,'' 2020.

\bibitem{deeva2023evaluating}
I.~Deeva, N.~Amerkhanova, and A.~Kropacheva, ``Evaluating robustness of tabular models under meta-features based shifts,'' {\em arXiv preprint}, 2023.
\newblock AI Institute, ITMO University.

\bibitem{malinin2022shifts20extendingdataset}
A.~Malinin, A.~Athanasopoulos, M.~Barakovic, M.~B. Cuadra, M.~J.~F. Gales, C.~Granziera, M.~Graziani, N.~Kartashev, K.~Kyriakopoulos, P.-J. Lu, N.~Molchanova, A.~Nikitakis, V.~Raina, F.~L. Rosa, E.~Sivena, V.~Tsarsitalidis, E.~Tsompopoulou, and E.~Volf, ``Shifts 2.0: Extending the dataset of real distributional shifts,'' 2022.

\bibitem{taori2020measuringrobustnessnaturaldistribution}
R.~Taori, A.~Dave, V.~Shankar, N.~Carlini, B.~Recht, and L.~Schmidt, ``Measuring robustness to natural distribution shifts in image classification,'' 2020.

\bibitem{NEURIPS2019_97af07a1}
A.~Barbu, D.~Mayo, J.~Alverio, W.~Luo, C.~Wang, D.~Gutfreund, J.~Tenenbaum, and B.~Katz, ``Objectnet: A large-scale bias-controlled dataset for pushing the limits of object recognition models,'' in {\em Advances in Neural Information Processing Systems} (H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle Alch\'{e}-Buc, E.~Fox, and R.~Garnett, eds.), vol.~32, Curran Associates, Inc., 2019.

\bibitem{ribeiro-etal-2020-beyond}
M.~T. Ribeiro, T.~Wu, C.~Guestrin, and S.~Singh, ``Beyond accuracy: Behavioral testing of {NLP} models with {C}heck{L}ist,'' in {\em Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics} (D.~Jurafsky, J.~Chai, N.~Schluter, and J.~Tetreault, eds.), (Online), pp.~4902--4912, Association for Computational Linguistics, July 2020.

\bibitem{kolesnikov2023wildtabbenchmarkoutofdistributiongeneralization}
S.~Kolesnikov, ``Wild-tab: A benchmark for out-of-distribution generalization in tabular regression,'' 2023.

\bibitem{Borisov_2024}
V.~Borisov, T.~Leemann, K.~Seßler, J.~Haug, M.~Pawelczyk, and G.~Kasneci, ``Deep neural networks and tabular data: A survey,'' {\em IEEE Transactions on Neural Networks and Learning Systems}, vol.~35, p.~7499–7519, June 2024.

\bibitem{heaton2018deep}
J.~B. Heaton, N.~G. Polson, and J.~H. Witte, ``Deep learning in finance,'' {\em arXiv preprint arXiv:1602.06561}, 2018.

\bibitem{ozbayoglu2020deeplearningfinancialapplications}
A.~M. Ozbayoglu, M.~U. Gudelek, and O.~B. Sezer, ``Deep learning for financial applications : A survey,'' 2020.

\bibitem{NAYYAR202123}
A.~Nayyar, L.~Gadhavi, and N.~Zaman, ``Chapter 2 - machine learning in healthcare: review, opportunities and challenges,'' in {\em Machine Learning and the Internet of Medical Things in Healthcare} (K.~K. Singh, M.~Elhoseny, A.~Singh, and A.~A. Elngar, eds.), pp.~23--45, Academic Press, 2021.

\bibitem{Rajkomar2018ScalableAA}
A.~Rajkomar, E.~Oren, K.~Chen, A.~M. Dai, N.~Hajaj, M.~Hardt, P.~J. Liu, X.~Liu, J.~Marcus, M.~Sun, P.~Sundberg, H.~Yee, K.~Zhang, Y.~Zhang, G.~Flores, G.~E. Duggan, J.~Irvine, Q.~V. Le, K.~Litsch, A.~Mossin, J.~Tansuwan, D.~Wang, J.~Wexler, J.~Wilson, D.~Ludwig, S.~L. Volchenboum, K.~Chou, M.~Pearson, S.~Madabushi, N.~H. Shah, A.~J. Butte, M.~D. Howell, C.~Cui, G.~S. Corrado, and J.~Dean, ``Scalable and accurate deep learning with electronic health records,'' {\em NPJ Digital Medicine}, vol.~1, 2018.

\bibitem{leukel2021adoption}
J.~Leukel, J.~González, and M.~Riekert, ``Adoption of machine learning technology for failure prediction in industrial maintenance: A systematic review,'' {\em Journal of Manufacturing Systems}, vol.~61, pp.~87--96, 2021.

\bibitem{grinsztajn2022treebasedmodelsoutperformdeep}
L.~Grinsztajn, E.~Oyallon, and G.~Varoquaux, ``Why do tree-based models still outperform deep learning on tabular data?,'' 2022.

\bibitem{balestriero2021learninghighdimensionamounts}
R.~Balestriero, J.~Pesenti, and Y.~LeCun, ``Learning in high dimension always amounts to extrapolation,'' 2021.

\bibitem{DBLP:journals/corr/abs-2312-16243}
S.~Zhang, Y.~Luo, Q.~Wang, H.~Chi, W.~Li, B.~Han, and J.~Li, ``Are all unseen data out-of-distribution?,'' {\em CoRR}, vol.~abs/2312.16243, 2023.

\bibitem{hwang2024uncertaintymeasurementdeeplearning}
H.~Hwang and J.~Shin, ``Uncertainty measurement of deep learning system based on the convex hull of training sets,'' 2024.

\bibitem{Vanschoren_2014}
J.~Vanschoren, J.~N. van Rijn, B.~Bischl, and L.~Torgo, ``Openml: networked science in machine learning,'' {\em ACM SIGKDD Explorations Newsletter}, vol.~15, p.~49–60, June 2014.

\end{thebibliography}
